{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.datasets import fetch_mldata\n",
    "# mnist = fetch_mldata('MNIST original')\n",
    "# X, y = mnist['data'], mnist['target']\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '0', '4', ..., '4', '5', '6'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "z = X[36000].reshape(28,28)\n",
    "plt.imshow(z, cmap = matplotlib.cm.binary, interpolation ='nearest') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 149.,\n",
       "       255., 184.,  12.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  11., 133., 212., 253., 253., 253., 102.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 162., 236., 253., 253.,\n",
       "       253., 253., 253.,  55.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        35., 196., 253., 253., 253., 253., 253., 253., 239.,  18.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  89., 249., 253., 253., 253., 185.,\n",
       "       253., 253., 177.,  24.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 129.,\n",
       "       247., 253., 253., 165., 150., 205., 253., 139.,   3.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  89., 247., 253., 240., 131.,  85., 221.,\n",
       "       253., 253.,  84.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 187.,\n",
       "       253., 253., 236., 139., 252., 253., 253., 253.,  84.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  21., 253., 253., 253., 253., 253., 253.,\n",
       "       253., 253., 248.,  53.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  99.,\n",
       "       253., 253., 253., 253., 253., 214., 253., 253., 179.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   4., 186., 251., 253., 249., 172.,\n",
       "       133., 253., 253., 137.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  49.,  94.,   6.,   0., 212., 253., 253.,  39.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       126., 253., 253., 197.,   6.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  27., 234., 253., 253.,  94.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       100., 253., 253., 239.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  61., 249., 253., 253.,  79.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,\n",
       "       109., 253., 253., 193.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  66., 253., 253., 253.,  30.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       147., 253., 253., 182.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  99., 248., 253., 222.,  13.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "\n",
    "X_test = X[60000: ]\n",
    "y_test = y[60000: ]\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = train_set, test_size=test_set, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_set_5 = np.where(y_train == '5', 1, 0)\n",
    "y_train_set_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_set_5 = np.where(y_test == '5', 1, 0)\n",
    "y_test_set_5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "# Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
    "model.fit(X_train, y_train_set_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train[36000].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_5_classifier = model.predict(X_test)\n",
    "predict_5_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[[False]\n",
      " [False]\n",
      " [False]\n",
      " ...\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "fit_never_5_classifier = never_5_clf.fit(y_test_set_5)\n",
    "predict_never_5_classifier = never_5_clf.predict(y_test_set_5)\n",
    "print(fit_never_5_classifier)\n",
    "print(predict_never_5_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9108,    0],\n",
       "       [ 892,    0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = y_test_set_5\n",
    "y_pred = predict_never_5_classifier\n",
    "confusion_matrix_never_5_classifier = confusion_matrix(y_true, y_pred)\n",
    "confusion_matrix_never_5_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_never_5_classifier = precision_score(y_true, y_pred)\n",
    "precision_never_5_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_never_5_classifier = recall_score(y_true, y_pred)\n",
    "recall_never_5_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score_never_5_classifier = f1_score(y_true, y_pred)\n",
    "f1_score_never_5_classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9108"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accur_score = accuracy_score(y_true, y_pred)\n",
    "accur_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9034,   74],\n",
       "       [ 147,  745]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_5_classifier = y_test_set_5\n",
    "y_pred_5_classifier = predict_5_classifier\n",
    "confusion_matrix_5_classifier = confusion_matrix(y_true_5_classifier, y_pred_5_classifier)\n",
    "confusion_matrix_5_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9096459096459096"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_5_classifier = precision_score(y_true_5_classifier, y_pred_5_classifier)\n",
    "precision_5_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8352017937219731"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_5_classifier = recall_score(y_true_5_classifier, y_pred_5_classifier)\n",
    "recall_5_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8708357685563999"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score_5_classifier = f1_score(y_true_5_classifier, y_pred_5_classifier)\n",
    "f1_score_5_classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9779"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accur_score_5_classifier = accuracy_score(y_true_5_classifier, y_pred_5_classifier)\n",
    "accur_score_5_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The probability cutoff for 5_classifier model is 0.5\\nwhereas, the probability cutoff fro never_5_classifier is 0.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the probability cutoff you are using to decide the classes?\n",
    "\"\"\"The probability cutoff for 5_classifier model is 0.5\n",
    "whereas, the probability cutoff fro never_5_classifier is 0.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The 5_classifier model is better as they have values which are nearly to 1 whereas in never_5_classifier the values\\nare '0'  it considered as worst.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"The 5_classifier model is better as they have values which are nearly to 1 whereas in never_5_classifier the values\n",
    "are '0'  it considered as worst.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 5_classifier \n",
    "# pos_labelint or str, default=None\n",
    "\n",
    "# The label of the positive class. When pos_label=None, if y_true is in {-1, 1} or {0, 1}, \n",
    "# pos_label is set to 1, otherwise an error will be raised.\n",
    "\n",
    "from sklearn import metrics\n",
    "fpr1, tpr1, thresholds1 = metrics.roc_curve(y_true_5_classifier, y_pred_5_classifier,pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For never_5_classifier \n",
    "from sklearn import metrics\n",
    "fpr2, tpr2, thresholds2 = metrics.roc_curve(y_true, y_pred,pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyU1b3H8c+PhCxsYQkQBAKIIG6gGAF3BJHFhXq7aHFprb3WW3HXutRq3dpaa0tdKVVr7cbtrbYssogrbiigyKZoRIWwbxK2hMzMuX88SZwskAnM5Jln5vt+vfJKJvMk+T0SvhzPnPM75pxDRESCr5nfBYiISHwo0EVEUoQCXUQkRSjQRURShAJdRCRFZPr1g/Pz813Pnj39+vEiIoG0cOHCzc65jvU951ug9+zZkwULFvj140VEAsnMvtzXc5pyERFJEQp0EZEUoUAXEUkRCnQRkRShQBcRSRENBrqZPW1mG81s6T6eNzN72MyKzWyxmQ2Mf5kiItKQWEbozwCj9vP8aKBP5dsVwBMHX5aIiDRWg+vQnXNzzaznfi4ZCzzrvD6888ysrZl1cc6ti1ONIiKBtbM8xPrte1i/vZz120o5ZPlT5PYbxnFDhsf9Z8VjY1FXYHXU45LKz9UJdDO7Am8UT2FhYRx+tIiIP5xzbN21l/WlZazfXlb9ft32MjaUVr7fXsaO8hAAR9kXPNB8Ekc3+4J3ykshSQPd6vlcvadmOOcmAZMAioqKdLKGiCSlUDjCpp3l1aEcHdLV4V1axt5QpMbXNTPo1DqHznk5HNaxFacclk/XVsbp6/9En0+fIpLbnr2jn+HEY85PSN3xCPQSoHvU427A2jh8XxGRuCurCNcN58qP15WWsX77HjbtKCdSa8iZldGMgrwcCvJyOLZ7W7pUflzQJqf68x1bZZOZEfXS5Kp5MGU8bPkUjr2YjJH3kZHbLmH3Fo9AnwqMN7PJwGBgu+bPRaSpOefYUR6qDueq6Y/1lSG9vrSc9dv3sG13RZ2vbZ2dSee8HLrk5dC3U8fqgO6Sl0PnNjl0yculXYvmmNU3IVGP8h3w8j3w3h8hrztc/DwcFv8pltoaDHQz+wcwFMg3sxLgLqA5gHNuIjADGAMUA7uByxJVrIikp0jEsXX33johXXu+etfecJ2v7dAyi4K8HA7Jy2FgYdsaIV0V3K2y49insPglmHYdbC+BwT+CYT+D7Fbx+/77Ecsql+828LwDropbRSKSVirCETbuKI8aVe+pMyWyobSMinDNOZCMZkbn1tl0zsuhX0FrhvbtREFeNgV5uRS08UbXndpkk52Z0TQ3snsrzP4pfPh3yO8LP5gFhUOa5mdX8q19roikvj17w6wvrSekK4N63fYyNu8sx9War87ObFY9R13Uox0FeblRI2vv8/mtssloFuMUSKItnwIv3AS7t8CpN8FpN0PznCYvQ4EuIo3mnKN0T4h1pXtqBHTtZXvb99Sdr26Tk1k51ZHLEQVtqueuq15c7JKXQ15uI+ar/bRjPcy4CT6aBl0GwMXPQZf+vpWjQBeRGiIRx+Zd5fWuqV4XFdx7KurOV+e3yqZLXg7d2rXghJ7tq1eBdMnzlvIVtMmhZTznq/3iHCz6G8y+HSrK4Myfw4lXQ4a/95YC/2VFJFZ7QxE2lNazpjrq/YbSMkK11uxlNjM6V46gjzykDcP6daqzbK9T6xyyMtOg39+2L2HatbDyVSg8Cc57BPIP87sqQIEukjJ2lYdqrKmumrtev72c9aXe+807y+t8XW7zjOr56cG92lev/CioXAnSOS+b/JbZNEuW+Wq/RMLeMsSX7wEzGPMbKLocmiXPP2IKdJEk55zjq90VNeao61u2t6MsVOdr27ZoXj2CPqZrXvWLitHL9trkZAZjvtpPm1bA1Kth9btw2JlwzgRo273hr2tiCnQRH4Ujjs2VW8y9kfUe1pXWna8ur7XF3Aw6Vs5X9+zQkhMP7eAt18vLpqBNbvUIOzeriZbspapwBbw1AV7/NWS1hPMnQf/veH8ASUiBLpIg5aEwG7aX179srzKoN+4oJ1xrvrp5hlWPpPt3a8tZR369trpqFUjH1tk0z0ie/9VPSWs/gClXw4YlcNT5MPpBaNXR76r2S4EucgCqWqLWXlcdvTJky669db6uZVZG9Rz1Sb3zq1d/dInqB9K+RZbmq/1UsQde+xW8/Qi07AgX/A2OOMfvqmKiQBeJUrslao1le1Ej7J3ldeer27VoXr0BZkCt5k1VH7fOae7DXUnMvnjLmyvf+hkcdwmcdR/ktvW7qpgp0CVt1NcStWanvT1sKC3fZ0vUgqiWqFVTH1XTIJ3b5JDTXPPVgVVWCi/fDfOfhLY94NIpcOhQv6tqNAW6pISyinC9a6rXRXXZq7clamaz6lAeWNju61ao1fPVueS3yqrZElVSy6dzvGZapWtgyI9h2B3eC6ABpECXpBbdErXuyPrrZXv7aolaNS/dt1PHr+erD7QlqqSW3Vth1m2weDJ07AeXz4HuJ/hd1UFRoItvIhHHll17o+am91Q3bIqer969n5ao3drlcnyPdpVz1Lk1DhuIa0tUSR3OwbJ/w4yboewrOP0WOPVGyMz2u7KDpt94SYivW6J6OxS9HYs1p0Qa2xK1as66SVuiSmopXQcv3AgrXoBDjoPzpkDB0X5XFTcKdGm06Jao++qydyAtUbvk5dAhmVqiSupwDj74C8y+A8LlMOJeb77c52Za8ZZadyMHpb6WqPUdjruvlqhe34+cmi1Ro5btBaYlqqSWrZ/DtGvg87nQ4xQ472Ho0NvvqhJCgZ4mIpVbzOubo45u5FRWUXeLeYeW3hbzwg4tGNSrfZ211QV5ObTI0q+SJJlIGN79A7xyL1gGnPM7GPj9pGqmFW/6W5gCqlqi1u609/VxXuUxtUQd3q9TjU57adUSVVLLxo9gynhYswD6jPTCPK+r31UlnAI9yUW3RP16ZB3dErWMzTvrbjGvaolakPd1S9To5XpqiSopKbQX3vwdzH0QctrAN5+Co7+ZtM204k2B7pOqlqg1pz/qLttrTEvU6GV7aokqaWfNQq+Z1sZlcPS3YPQD0DLf76qalAI9AWq2RN1Tua287nRIY1uiVo2w1RJVJMre3fDaL+Cdx6BVAXx3Mhw+2u+qfKFAb6TaLVHrW7ZXX0vUrIxmdM7LpqBNzZao0cv21BJVpJE+f8NbwbJ1JRz/fRhxD+Tk+V2VbxToUXaUVdRZ/VH7sIGt+2mJ2iUvl95qiSqSeGXbYc5dsPBP0K4XfG8a9DrN76p8lxaBXtUSdV+tUKtG2PW1RG3fMqt6BH1sYdsazZvUElXEBytmwfTrYed6OOlqGHo7ZLXwu6qkEPhAj26JWnuOurEtUWufYq6WqCJJZNdmmHkLLP0XdDoSLvgrdDve76qSSqAD/Zp/fMD0xWtjbokavWxPLVFFAsI5WPoczPyJ17d86O1wyvWQmeV3ZUkn0IH+/qpt9Ctow0VDCisbN3mH46olqkiK2L4GXrgBPpkFXY+H8x6Fzkf6XVXSCnSghyOOow5pw0WDe/hdiojEUyQC7/8Z5twJ4QoY+QsYfCU00xTo/gQ60EMRR2aGRuIiKWXLZzDtWvjiDW/lyrm/h/aH+l1VIAQ60MMRp1arIqkiHIJ5j8Or90NGFpz7MAy8NG227cdDTK8KmtkoM1thZsVmdms9z+eZ2TQz+9DMlpnZZfEvta5QOEJmCndOE0kbG5bBUyNgzs+g9zC46l04/nsK80ZqcIRuZhnAY8AIoASYb2ZTnXPLoy67CljunDvXzDoCK8zsb865urtw4iji0AhdJMhC5fDGQ95bTlv41tNw1H8pyA9QLFMug4Bi59xKADObDIwFogPdAa3NW1rSCtgK1N2lE2ehSESBLhJUJQu8FrebPoL+F8DIX0LLDn5XFWixBHpXYHXU4xJgcK1rHgWmAmuB1sAFzrlIrWswsyuAKwAKCwsPpN4aNIcuEkB7d8Er93vz5W0OgXH/hL4j/a4qJcQS6PUlZq2tPIwEFgHDgN7AHDN7wzlXWuOLnJsETAIoKiqq/T0aLRRxZCrQRYJj5eteM61tX0DR5XDmz72+5RIXsQR6CdA96nE3vJF4tMuAXznnHFBsZp8D/YD34lJlPSIRh9Mcukgw7PnKe8Hz/WehfW/4/gzoebLfVaWcWAJ9PtDHzHoBa4ALgXG1rlkFDAfeMLPOwOHAyngWWlvVcWoaoYskuY9fgOk3wK6NcPK1MPQ2aJ7rd1UpqcFAd86FzGw8MBvIAJ52zi0zsysrn58I3As8Y2ZL8KZobnHObU5g3UScF+gZWrYokpx2bvL6ryx7HjofDd/9B3Qd6HdVKS2mjUXOuRnAjFqfmxj18VrgrPiWtn9VI3T11xJJMs7B4n/CrFu8F0DPuANOuQ4y1GY60QK7UzQc1ghdJOlsL/F6lX/6InQ7wWum1amf31WljcAGeijirYrUHLpIEohEYOHT3ilCLgKjHoBB/61mWk0ssIEerp5yUaCL+GpzMUy9Gla9DYcO9Zpptevpc1HpKbCBrlUuIj4Lh+CdR+G1X0JmNox9DI69SNv2fRTYQNcIXcRH65fAlKtg3YfQ7xw4+yFoXeB3VWkv8IGufugiTShUDnMfhDd/B7nt4Nt/hiPHalSeJAIb6FVTLs30iyTSNFa9682Vb14BA8bByPuhRXu/q5IogQ306hG6li2KJFb5TnjlXnj3D5DXDS5+Dg470++qpB6BDfSqZYuaQxdJoM9e8Y6D+2oVDLoCht8J2a39rkr2IbCBHtYqF5HE2bMNZt8Bi/4KHfrAZbOgx4l+VyUNCHygZ+hFUZH4+mgavHAj7NoMp9wAp98CzXP8rkpiEPhA1whdJE52bICZN8PyKVBwjHfwxCHH+l2VNEJgA726OZdWuYgcHOfgw3/ArNugYo83T37SNWqmFUCBDXRtLBKJg69WwbTr4LOXofsQOO8R6NjX76rkAAU20EPaWCRy4CIRmP8kvPRz7/HoB+GEH4KWAQdaYAM9XL1sUb+AIo2y+VOYMh5Wz4Pew+HcCdD24A9tF/8FONC993pRVCRG4Qp4+2F47QHvCLhvPAEDvqtt+ykkwIGujUUiMVv3oddMa/0Sr/fK6AehdWe/q5I4C2ygh/SiqEjDKsrg9V/BWw9Dy3z4zl/gyPP8rkoSJLCBrlUuIg348h2YOh62FMOxF8PI+7wOiZKyAhvoobA2FonUq3wHvHQ3zP+j92LnJf+G3sP8rkqaQGADXSN0kXoUv+StK99eAoOvhGE/g+xWflclTSS4ge7UPlek2u6tMPt2b8dnfl/4wWwoHOx3VdLEAhvoelFUBG/b/vIpMOMmr0PiqTfBaTermVaaCmygh8Natihpbsd6ryvix9OhywC4+Hno0t/vqsRHgQ10jdAlbTkHi/7mTbGEyuHMu+HE8ZAR2L/OEieB/Q1Q+1xJS9u+8E4QWvkaFJ7kNdPKP8zvqiRJBDbQNUKXtBIJw3t/hJfvBmsGZz8Ex/9AzbSkhsAGekQjdEkXGz+GqVdDyXtw2Ag453fQtrvfVUkSCmyga4QuKS9cAW9OgLm/hqxWcP4k6P8dNdOSfYrp/9fMbJSZrTCzYjO7dR/XDDWzRWa2zMxej2+ZdYUjjmYGpl9uSUVrP4BJQ+HV+6DfOXDVezDgAoW57FeDI3QzywAeA0YAJcB8M5vqnFsedU1b4HFglHNulZl1SlTBVUIRp01Fknoq9sBrv4S3H4GWneDCv0O/s/2uSgIilimXQUCxc24lgJlNBsYCy6OuGQc875xbBeCc2xjvQmsLRyKabpHU8sVb3lz51s9g4KUw4l7Ibet3VRIgsQxxuwKrox6XVH4uWl+gnZm9ZmYLzezS+r6RmV1hZgvMbMGmTZsOrOJK3ghdgS4poKwUpt8Az4yBSAguneItR1SYSyPFMkKvLzVdPd/neGA4kAu8Y2bznHOf1Pgi5yYBkwCKiopqf49GiUQcGTpPVILukxdh+nVQuhaGXAXDfgpZLf2uSgIqlkAvAaLXSHUD1tZzzWbn3C5gl5nNBQYAn5AgGqFLoO3aArNuhSX/hI794PI50P0Ev6uSgItlymU+0MfMeplZFnAhMLXWNVOAU80s08xaAIOBj+Jbak3hiNMcugSPc7D0OXhsECx7Hk6/FX40V2EucdHgCN05FzKz8cBsIAN42jm3zMyurHx+onPuIzObBSwGIsCTzrmliSw8FHFkaAmXBEnpOnjhBlgxAw45DsZOhc5H+V2VpJCYNhY552YAM2p9bmKtxw8CD8avtP0Law5dgsI5eP9ZePFnEC6Hs+6Dwf+jZloSd4H9jdI6dAmErSu9Zlqfz4Uep8B5D0OH3n5XJSkqsIEe0Ry6JLNIGOY9Aa/cB80y4ZwJMPB7aqYlCRXYQA9FIlrlIslpw3KYOh7WLIS+o+Ds30Je7a0bIvEX2EDXKhdJOqG98OZvYe5vIKcNfPMpOPqb6r8iTSawgR5SoEsyWbMQpoyHjcvhmG/DqF9By3y/q5I0E9hA1whdksLe3fDq/TDvcWhVAN+dDIeP9rsqSVOBDfRQWDtFxWefz4Wp18C2z+H4y2DE3ZCT53dVksYCG+hhpxG6+KRsO8y5ExY+A+16wfemQa/T/K5KJMCBHnFkNc/wuwxJNytmwvTrYecGOOlqGHo7ZLXwuyoRIMCBrhdFpUnt2gwzb4Gl/4JOR8GFf4Oux/tdlUgNgQ10HXAhTcI5WPIvmPkTKN/hjchPuR4ys/yuTKSOwAZ6KKwRuiTY9jVeM61PZkHXIhj7KHQ6wu+qRPYpsIEeVj90SZRIBN5/Bl680ztBaOQvYPCV0Eyv2UhyC26ga5WLJMKWz7yliF++6a1cOfdhaN/L76pEYhLcQNcIXeIpHPI2B716P2Rke2d6HneJtu1LoAQ20L05dHWukzhYv9RrprX2Azj8bDj7IWjTxe+qRBotsIHubf33uwoJtFA5vPGQ95bTFr71JzjqfI3KJbACG+jeOnQluhyg1fO9Ufmmj6H/BV4zrRbt/a5K5KAENtDD6ocuB2LvLu/QiXlPQJtDYNz/Qd+z/K5KJC4CG+jaKSqNtvI1bwXLV1/CCT+E4Xd5fctFUkRgAz2iVS4Sqz1fwYt3wAd/gfa94fszoOfJflclEneBDfRQxJGRoUCXBnz8Aky/AXZtgpOvg6G3QvNcv6sSSYjABno44sjQagTZl50bvf4ry/4NnY+BcZPhkOP8rkokoQIZ6M45Qppykfo4B4v/F2bd6r0AOuwOb2Se0dzvykQSLpCBHnHeey1blBq+Wu31Ki+eA90Gec20Oh7ud1UiTSaQgR6KRADI1By6gNdMa8FT8NLPwUVg1AMw6L/VTEvSTiADvTLPtWxRYHMxTL0aVr0Nh54B5/4e2vXwuyoRXwQy0KtH6Ar09BUOwTuPwKu/hOY5MPZxOHactu1LWgtkoIcrJ9Gb6S9velq32Nu2v+5D6HeO10yrdYHfVYn4LpCBHqoMdM2hp5mKMpj7a3hzArToAN95Fo4c63dVIkkjkIFeNULXHHoaWfWuNyrf/AkMGAcj71czLZFaYlr3Z2ajzGyFmRWb2a37ue4EMwub2bfiV2Jd1SN0BXrqK98JM34CT4+Eij1w8XNw/hMKc5F6NDhCN7MM4DFgBFACzDezqc655fVc9wAwOxGFRotUj9C1Dj2lFb8M066D7au9ZYjD74Ts1n5XJZK0YplyGQQUO+dWApjZZGAssLzWdVcDzwEnxLXCemiEnuL2bIPZP4VFf4MOfeCymdDjRL+rEkl6sQR6V2B11OMSYHD0BWbWFTgfGMZ+At3MrgCuACgsLGxsrdXClcsWNYeegpZPhRk3wa7NcMoNcPot3rJEEWlQLIFeX2q6Wo8nALc458K2n6WEzrlJwCSAoqKi2t8jZiG9KJp6dmzwgvyjqVBwDFz0f9BlgN9ViQRKLIFeAnSPetwNWFvrmiJgcmWY5wNjzCzknPtPXKqsJRRWoKcM52DR32H27d6LnsPvgpOuVjMtkQMQS6DPB/qYWS9gDXAhMC76Audcr6qPzewZYHqiwhy+XraoOfSA2/YlTL8OPnsFCk+E8x6B/D5+VyUSWA0GunMuZGbj8VavZABPO+eWmdmVlc9PTHCNdYSdRuiBFonA/D/CS3d7W/XH/AaKLgetWhI5KDFtLHLOzQBm1PpcvUHunPv+wZe1f1+P0BUAgbPpE6+Z1up50Hs4nDsB2h74C+Qi8rVA7hTVHHoAhSvgrd/D6w9A8xbwjYkw4EI10xKJo0AGurb+B8zaRd62/fVLvN4rY34DrTr5XZVIyglkoIe0Dj0YKvZ4I/K3HoaW+XDBX+GIc/2uSiRlBTLQtcolAL58xxuVbymG4y6Gs+6D3HZ+VyWS0gId6BqhJ6HyHd7qlfl/9F7svOQ/0PsMv6sSSQuBDnT1Q08yn87xmmmVroHB/wPD7oDsVn5XJZI2Ahnoas6VZHZvhVm3weLJkH84XP4idB/kd1UiaSeQga4j6JKEc7D8PzDjZq9D4mk3e2+Z2X5XJpKWAhnoIW0s8t+O9fDCjfDxdOhyLFzyb6+ploj4JpCBXt0+V3PoTc85+OCvXr/ycDmMuAeGXAUZgfxVEkkpgfxbGPbyXHPoTW3bFzDtWlj5GvQ4Gc59GPIP87sqEakU0EDXxqImFQnDe5Pg5XvAMuDs38Lxl6mZlkiSCWSga5VLE9r4sbdBqGQ+HDbCa6aV183vqkSkHoEM9OpVLgr0xAnthbcmwNwHIasV/Ncf4Zhvq5mWSBILZKBrhJ5ga973WtxuWApHfxNGPQCtOvpdlYg0IJCBrq3/CVKxB179BbzzKLTqDBf+A/qN8bsqEYlRoANd69Dj6Is3vVH51pUw8HvecsTctn5XJSKNEMhAD1XvFPW5kFRQVgov3QULnoZ2PeHSqXDo6X5XJSIHIJCBHo5EyGxmmF6gOzifzIbp18OOdXDieDjjdshq6XdVInKAAhnooYjTCpeDsWsLzLoVlvwTOh4B33kWuhX5XZWIHKRABno47LTC5UA4B0ufg5k/8aZaTr8VTr0RMrP8rkxE4iCQgR6KOK1waazStV4zrRUz4JCBMPZR6HyU31WJSBwFMtAjTiP0mDkH7/8ZXvwZhCu8o+CG/BiaZfhdmYjEWSAD3Ruha8lig7auhKnXwBdvQM9T4dzfQ4feflclIgkSyEDXHHoDImGY9wS8ch9kNIdzJnhry/WPoEhKC2Sgaw59PzYs95pprVkIfUd5nRHzuvpdlYg0gUAGejgSUaDXFtoLb/4W5v4GctrAN5/y+rBorb5I2ghkoIcimnKpoWShNyrfuNzriDjqAWjZwe+qRKSJBTLQI05TLgDs3Q2v3g/zHodWBfDd/4XDR/ldlYj4JJCBHgor0Pl8rtdMa9sX3ulBI+6GnDy/qxIRH8W07MHMRpnZCjMrNrNb63n+IjNbXPn2tpkNiH+pXwtHHJnpekB02XZvKeKfzwUMvjfdO0VIYS6S9hocoZtZBvAYMAIoAeab2VTn3PKoyz4HTnfObTOz0cAkYHAiCoY0Xoe+YqbXTGvnBjjpGhh6G2S18LsqEUkSsUy5DAKKnXMrAcxsMjAWqA5059zbUdfPAxJ66GQ44kirAfquzV7/laXPQaej4MK/Q9eBflclIkkmlkDvCqyOelzC/kfflwMz63vCzK4ArgAoLCyMscS6QpFIehxu4Rws+T+YeQuU74AzfgonX6dmWiJSr1gCvb6xsKv3QrMz8AL9lPqed85NwpuOoaioqN7vEYtIJA2On9teAtNvgE9nQ9cir5lWpyP8rkpEklgsgV4CdI963A1YW/siM+sPPAmMds5tiU959QtFImQ3D+QCnYZFIrDwTzDnLnBhGPlLGPwjNdMSkQbFkorzgT5m1gtYA1wIjIu+wMwKgeeBS5xzn8S9ylrCqbr1f8tn3gqWL9+EXqd7zbTa9/K7KhEJiAYD3TkXMrPxwGwgA3jaObfMzK6sfH4icCfQAXi88li4kHMuYUfgpNxO0XAI5j0Gr/4CMrLhvEfhuIu1bV9EGiWmeQvn3AxgRq3PTYz6+IfAD+Nb2r6FI45mqRJ265fAlPGwbhEcfjac/RC06eJ3VSISQIGciA6lwsaiUDnMfRDe/B3ktoNvPwNHfkOjchE5YIEM9EjQNxatfs8blW9eAf0vhFG/hBbt/a5KRAIukIEe2Dn0vbvg5Xvh3YnQpitc9C/oM8LvqkQkRQQy0AO5yuWzV2HaNfDVKjjhhzD8Lq9vuYhInAQy0L2dogEJ9D1fwYs/hQ/+Cu17w2UzocdJflclIikokIEejjiaBSHQP5oOL9wIuzbBKdfD6bdA81y/qxKRFBXIQE/6OfSdG2HGzbD8P9D5GBg3GQ45zu+qRCTFBTLQk3YO3Tn4cDLMuhUqdsOwn8HJ10JGc78rE5E0ENhAT7oR+lerYfp1UPwSdBvkNdPqeLjfVYlIGglkoCfVAReRCCx4Cl76uTdCH/1rbxWLmmmJSBMLZKAnzQh986feuZ6r3oFDz/CaabXr4XdVIpKmAhfozjn/V7mEK+DtR+C1X0HzHBj7OBw7Ttv2RcRXgQv0cMQ7F8O3Efq6D71t++sXwxHnwpiHoHVnf2oREYkSvEB3XqA3+SqXijKY+2t4cwK06ADfeRaOHNu0NYiI7EfwAt2PEfqqed6ofMunMGAcjLxfzbREJOkELtBDkSYcoZfvhJfvgfcmQV53uPg5OOzMxP9cEZEDELhAD4ebaIRe/BJMux62r4ZBV8DwOyG7VWJ/pojIQQhcoCd8hL57K8z+KXz4d+jQB34wCwqHJOZniYjEUeACPVwd6AnYWLR8CrxwE+zeAqfeCKf9xFuWKCISAMELdJeAKZcd62HGTfDRNCjo782Vd+kfv+8vItIEghfo4ThOuTgHi/4Os2/zliWe+XM4cbyaaYlIIAUu0EORCMDBHxK97UuYdi2sfBUKT4TzHoH8PnGoUETEH4EL9PDBvigaCcP8J+Glu72t+mN+A0WXQ7I0+xIROUCBC/TQwWws2rTCa6a1+l1vPfk5v4O2hXGuUETEH4EL9KoRerPGNMIKV8BbE1s/5zkAAAWcSURBVOD1X0NWSzj/D9D/AjXTEpGUEthAj3kOfe0ib9v+hiVw5DdgzIPQqlMCKxQR8UfgAj0U6zr0ij1ee9u3H4GW+XDBX73uiCIiKSpwgR5Tc64v3/bmyrcUw3GXwFn3Qm67JqpQRMQfgQv0qmWL9a5yKSuFl+/2VrG0LYRL/gO9z2jiCkVE/BG4QN/nCP3TOTDtOihdA0N+DMPu8F4AFRFJE4EL9Ko59Ooj6HZvhVm3weLJkH84XP4idB/kY4UiIv6IaTeNmY0ysxVmVmxmt9bzvJnZw5XPLzazgfEv1ROpGqEbsPR5ePQEWPovr5HWlW8ozEUkbTU4QjezDOAxYARQAsw3s6nOueVRl40G+lS+DQaeqHwfd6GIoxPb6Pnyj+CL2dDlWLh0ChQcnYgfJyISGLFMuQwCip1zKwHMbDIwFogO9LHAs845B8wzs7Zm1sU5ty7eBbdf8xovZd9Mq9VhGHEPDLkKMgI3cyQiEnexTLl0BVZHPS6p/Fxjr8HMrjCzBWa2YNOmTY2tFYDcLn1Z3fJoNl/yKpx8rcJcRKRSLGlY34JvdwDX4JybBEwCKCoqqvN8LI4+ZiAcM+dAvlREJKXFMkIvAbpHPe4GrD2Aa0REJIFiCfT5QB8z62VmWcCFwNRa10wFLq1c7TIE2J6I+XMREdm3BqdcnHMhMxsPzAYygKedc8vM7MrK5ycCM4AxQDGwG7gscSWLiEh9YnpF0Tk3Ay+0oz83MepjB1wV39JERKQxdEyPiEiKUKCLiKQIBbqISIpQoIuIpAjzXs/04QebbQK+PMAvzwc2x7GcINA9pwfdc3o4mHvu4ZzrWN8TvgX6wTCzBc65Ir/raEq65/Sge04PibpnTbmIiKQIBbqISIoIaqBP8rsAH+ie04PuOT0k5J4DOYcuIiJ1BXWELiIitSjQRURSRFIHejIdTt1UYrjniyrvdbGZvW1mA/yoM54auueo604ws7CZfasp60uEWO7ZzIaa2SIzW2Zmrzd1jfEWw+92nplNM7MPK+850F1bzexpM9toZkv38Xz888s5l5RveK16PwMOBbKAD4Eja10zBpiJd2LSEOBdv+tugns+CWhX+fHodLjnqOtewev6+S2/626CP+e2eOf2FlY+7uR33U1wz7cDD1R+3BHYCmT5XftB3PNpwEBg6T6ej3t+JfMIvfpwaufcXqDqcOpo1YdTO+fmAW3NrEtTFxpHDd6zc+5t59y2yofz8E6HCrJY/pwBrgaeAzY2ZXEJEss9jwOed86tAnDOBf2+Y7lnB7Q2MwNa4QV6qGnLjB/n3Fy8e9iXuOdXMgd63A6nDpDG3s/leP/CB1mD92xmXYHzgYmkhlj+nPsC7czsNTNbaGaXNll1iRHLPT8KHIF3fOUS4FrnXKRpyvNF3PMrpgMufBK3w6kDJOb7MbMz8AL9lIRWlHix3PME4BbnXNgbvAVeLPecCRwPDAdygXfMbJ5z7pNEF5cgsdzzSGARMAzoDcwxszecc6WJLs4ncc+vZA70dDycOqb7MbP+wJPAaOfcliaqLVFiueciYHJlmOcDY8ws5Jz7T9OUGHex/m5vds7tAnaZ2VxgABDUQI/lni8DfuW8CeZiM/sc6Ae81zQlNrm451cyT7mk4+HUDd6zmRUCzwOXBHi0Fq3Be3bO9XLO9XTO9QT+Bfw4wGEOsf1uTwFONbNMM2sBDAY+auI64ymWe16F938kmFln4HBgZZNW2bTinl9JO0J3aXg4dYz3fCfQAXi8csQacgHuVBfjPaeUWO7ZOfeRmc0CFgMR4EnnXL3L34Igxj/ne4FnzGwJ3nTELc65wLbVNbN/AEOBfDMrAe4CmkPi8ktb/0VEUkQyT7mIiEgjKNBFRFKEAl1EJEUo0EVEUoQCXUQkRSjQRURShAJdRCRF/D8VcoKqYOkpgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr1, tpr1) \n",
    "plt.plot(fpr2, tpr2) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9135385341029717"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For 5_classifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score_5_classifier = roc_auc_score(y_true_5_classifier, y_pred_5_classifier)\n",
    "roc_auc_score_5_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For never_5_classifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score_never_5_classifier = roc_auc_score(y_true, y_pred)\n",
    "roc_auc_score_never_5_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The roc_auc_score always runs from 0 to 1 The 5_classifier is having 0.9 which is better when compared with \\nnever_5_classifier with 0.5'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"The roc_auc_score always runs from 0 to 1 The 5_classifier is having 0.9 which is better when compared with \n",
    "never_5_classifier with 0.5\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
